{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append(\"C://Users/Admin/Desktop/000-data_science/sem2-project_1/treepedia_dl_public-master\")\n",
    "\n",
    "import model_lib as treepedia_dl\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model( \"C://Users/Admin/Desktop/000-data_science/sem2-project_1/treepedia_dl_public-master/weights_test.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 1000)              25636712  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               256256    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,090,601\n",
      "Trainable params: 26,037,481\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change labelled png data into two channel label jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the png file paths for test data\n",
    "fix_png = \"C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/fix_png.txt\"\n",
    "with open(fix_png, 'r') as training:\n",
    "        content = training.readlines()\n",
    "        png_paths = []\n",
    "\n",
    "        for lines in content: \n",
    "                lines = lines.replace('\\n', '')\n",
    "                png_paths.append(lines)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.45792-103.769025-0.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.45792-103.769025-60.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.45792-103.769025-120.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.45792-103.769025-180.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.45792-103.769025-240.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.45792-103.769025-300.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.46517-103.7589044-0.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.46517-103.7589044-60.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.46517-103.7589044-120.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.46517-103.7589044-180.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.46517-103.7589044-240.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.46517-103.7589044-300.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4574946-103.7690224-0.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4574946-103.7690224-60.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4574946-103.7690224-120.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4574946-103.7690224-180.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4574946-103.7690224-240.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4574946-103.7690224-300.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4576324-103.7689637-0.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4576324-103.7689637-60.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4576324-103.7689637-120.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4576324-103.7689637-180.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4576324-103.7689637-240.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4576324-103.7689637-300.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4578067-103.7675917-0.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4578067-103.7675917-60.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4578067-103.7675917-120.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4578067-103.7675917-180.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4578067-103.7675917-240.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4578067-103.7675917-300.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4581955-103.7692668-0.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4581955-103.7692668-60.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4581955-103.7692668-120.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4581955-103.7692668-180.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4581955-103.7692668-240.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4581955-103.7692668-300.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4583986-103.7694707-0.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4583986-103.7694707-60.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4583986-103.7694707-120.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4583986-103.7694707-180.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4583986-103.7694707-240.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4583986-103.7694707-300.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4586617-103.7687351-0.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4586617-103.7687351-60.png',\n",
       " 'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/1.4586617-103.7687351-120.png']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "png_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1.4574946', '103.7690224', 0],\n",
       " ['1.4574946', '103.7690224', 120],\n",
       " ['1.4574946', '103.7690224', 180],\n",
       " ['1.4574946', '103.7690224', 240],\n",
       " ['1.4574946', '103.7690224', 300],\n",
       " ['1.4574946', '103.7690224', 60],\n",
       " ['1.4576324', '103.7689637', 0],\n",
       " ['1.4576324', '103.7689637', 120],\n",
       " ['1.4576324', '103.7689637', 180],\n",
       " ['1.4576324', '103.7689637', 240],\n",
       " ['1.4576324', '103.7689637', 300],\n",
       " ['1.4576324', '103.7689637', 60],\n",
       " ['1.4578067', '103.7675917', 0],\n",
       " ['1.4578067', '103.7675917', 120],\n",
       " ['1.4578067', '103.7675917', 180],\n",
       " ['1.4578067', '103.7675917', 240],\n",
       " ['1.4578067', '103.7675917', 300],\n",
       " ['1.4578067', '103.7675917', 60],\n",
       " ['1.45792', '103.769025', 300],\n",
       " ['1.4581955', '103.7692668', 0],\n",
       " ['1.4581955', '103.7692668', 120],\n",
       " ['1.4581955', '103.7692668', 180],\n",
       " ['1.4581955', '103.7692668', 240],\n",
       " ['1.4581955', '103.7692668', 300],\n",
       " ['1.4581955', '103.7692668', 60],\n",
       " ['1.4583986', '103.7694707', 0],\n",
       " ['1.4583986', '103.7694707', 120],\n",
       " ['1.4583986', '103.7694707', 180],\n",
       " ['1.4583986', '103.7694707', 240],\n",
       " ['1.4583986', '103.7694707', 300],\n",
       " ['1.4583986', '103.7694707', 60],\n",
       " ['1.4586617', '103.7687351', 0],\n",
       " ['1.4586617', '103.7687351', 120],\n",
       " ['1.4586617', '103.7687351', 60],\n",
       " ['1.46517', '103.7589044', 0],\n",
       " ['1.46517', '103.7589044', 120],\n",
       " ['1.46517', '103.7589044', 180],\n",
       " ['1.46517', '103.7589044', 240],\n",
       " ['1.46517', '103.7589044', 300],\n",
       " ['1.46517', '103.7589044', 60]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "test_datas = []\n",
    "for file_name in os.listdir(\"images/mask/test_data\"):\n",
    "    if file_name.endswith('.jpg'):\n",
    "         # Split the file name into its components using the '-' separator\n",
    "        file_components = file_name.split('-')\n",
    "        # Extract the latitude, longitude, and heading information from the file name\n",
    "        lat = (file_components[0])\n",
    "        lng = (file_components[1])\n",
    "        heading = int(file_components[2].split('.')[0])\n",
    "        # Add the information to the dataframe as a new row\n",
    "        test_datas.append([lat, lng, heading])\n",
    "\n",
    "test_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_data in test_datas:\n",
    "    lat, lng, heading = test_data[0],test_data[1], test_data[2]\n",
    "    test_lbl = f'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/testlabel_png/{lat}-{lng}-{heading}.png'\n",
    "    img = Image.open(test_lbl)\n",
    "    img = img.convert('L')\n",
    "    # image = Image.fromarray(imgg)\n",
    "    \n",
    "    img.save(f'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/fixed_label/{lat}-{lng}-{heading}.jpg') \n",
    "    #f.write(image)\n",
    "\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# convert the png files to 2 channels jpg\n",
    "for line, test_label in zip(range(len(png_paths)), test_lbl):\n",
    "    lat, lng, heading = test_label[0],test_label[1], test_label[2]\n",
    "    img = Image.open(png_paths[line])\n",
    "    img = img.convert('L')\n",
    "    # image = Image.fromarray(imgg)\n",
    "    \n",
    "    img.save(f'C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/fixed_label/{lat}-{lng}-{heading}.jpg') \n",
    "    #f.write(image)\n",
    "\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 640)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if they have been successfully transformed\n",
    "plt.imread(\"C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/fixed_images/fixed_0.jpg\").shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load test data for preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_resize(image_loc):\n",
    "    '''\n",
    "    load image and ground truth label data with txt file consisting image data file paths\n",
    "    '''\n",
    "    test_data = []\n",
    "    test_gt = []\n",
    "    with open(image_loc, 'r') as training:\n",
    "        content = training.readlines()\n",
    "    for line in content:\n",
    "        paths = line.split()\n",
    "        if len(paths) == 2:\n",
    "            test_data.append(paths[0])\n",
    "            test_gt.append(paths[1].replace(\"\\n\", \"\"))\n",
    "        if len(paths) == 3:\n",
    "            test_data.append(paths[0] + \" \"+paths[1])\n",
    "            test_gt.append(paths[2].replace(\"\\n\", \"\"))\n",
    "    imgdata = []\n",
    "    for path1 in test_data:\n",
    "        imgdata.append((Image.open(path1)).resize(current_model[0:2]))\n",
    "    labeldata = []\n",
    "    for path in test_gt:\n",
    "        labeldata.append(np.sum(np.asarray((Image.open(path)).resize(current_model[0:2])) != 0)*1.0 /\n",
    "                         (current_model[0]*current_model[1]))\n",
    "    imgdata_array = np.zeros(\n",
    "        [len(imgdata), current_model[0], current_model[1], current_model[2]])\n",
    "    labeldata_array = np.zeros([len(imgdata), 1])\n",
    "    for i in range(len(imgdata)):\n",
    "        imgdata_array[i, :, :, :] = imgdata[i]\n",
    "        labeldata_array[i, :] = labeldata[i]\n",
    "    del (imgdata, labeldata)\n",
    "    return (imgdata_array, labeldata_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdata_array, labeldata_array = treepedia_dl.load_and_resize(\n",
    "    \"C://Users/Admin/Desktop/000-data_science/sem2-project_1/images/mask/jpg_test_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image array\n",
    "imgdata_array.shape\n",
    "np.save('test_data_array.npy', imgdata_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array of GVI ground truth\n",
    "labeldata_array\n",
    "np.save('true_GVI_test.npy', labeldata_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60094467],\n",
       "       [0.3126993 ],\n",
       "       [0.50051818],\n",
       "       [0.3052854 ],\n",
       "       [0.64861687],\n",
       "       [0.58444276],\n",
       "       [0.50061783],\n",
       "       [0.45487883],\n",
       "       [0.3458227 ],\n",
       "       [0.59105947],\n",
       "       [0.78125   ],\n",
       "       [0.67480469],\n",
       "       [0.00486288],\n",
       "       [0.        ],\n",
       "       [0.02188297],\n",
       "       [0.06437341],\n",
       "       [0.        ],\n",
       "       [0.01937181],\n",
       "       [0.36742666],\n",
       "       [0.06407446],\n",
       "       [0.29342714],\n",
       "       [0.48128587],\n",
       "       [0.17364876],\n",
       "       [0.05919165],\n",
       "       [0.064772  ],\n",
       "       [0.83442283],\n",
       "       [0.6038345 ],\n",
       "       [0.47981107],\n",
       "       [0.57226562],\n",
       "       [0.70304528],\n",
       "       [0.51311384],\n",
       "       [0.        ],\n",
       "       [0.24358259],\n",
       "       [0.05291374],\n",
       "       [0.10672433],\n",
       "       [0.        ],\n",
       "       [0.13757573],\n",
       "       [0.84703842],\n",
       "       [0.45762915],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('true_GVI_test.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test DCNN prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.3106264 ],\n",
       "       [0.5160212 ],\n",
       "       [0.18007785],\n",
       "       [0.09406929],\n",
       "       [0.11547126],\n",
       "       [0.2521316 ],\n",
       "       [0.13138202],\n",
       "       [0.04073031],\n",
       "       [0.05839574],\n",
       "       [0.04726631],\n",
       "       [0.6342129 ],\n",
       "       [0.29890087],\n",
       "       [0.22126643],\n",
       "       [0.22700313],\n",
       "       [0.17545329],\n",
       "       [0.31126994],\n",
       "       [0.23843314],\n",
       "       [0.35760412],\n",
       "       [0.23956876],\n",
       "       [0.3875342 ],\n",
       "       [0.19396795],\n",
       "       [0.18305703],\n",
       "       [0.31971508],\n",
       "       [0.3970952 ],\n",
       "       [0.05750674],\n",
       "       [0.08364543],\n",
       "       [0.0743855 ],\n",
       "       [0.09982818],\n",
       "       [0.13972105],\n",
       "       [0.07007068],\n",
       "       [0.09495103],\n",
       "       [0.10827843],\n",
       "       [0.21562845],\n",
       "       [0.2884954 ],\n",
       "       [0.11649828],\n",
       "       [0.1218613 ],\n",
       "       [0.49834064],\n",
       "       [0.2311715 ],\n",
       "       [0.25066155],\n",
       "       [0.19634311],\n",
       "       [0.40027127],\n",
       "       [0.59893364],\n",
       "       [0.04003099],\n",
       "       [0.07372795],\n",
       "       [0.16780147]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GVI predicted with DCNN model\n",
    "DCNN_pred = treepedia_dl.eval_batch(model, imgdata_array, 100, 1)\n",
    "DCNN_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Absolute GVI error is: 0.146651\n",
      "5-95 percentile of Absolute GVI error is (-0.356586, 0.073523)\n",
      "Correlation of predicted and true GVI is: 0.892504\n"
     ]
    }
   ],
   "source": [
    "# compute difference between prediction and true GVI\n",
    "diff = np.zeros([len(DCNN_pred), 1])\n",
    "for i in range(len(DCNN_pred)):\n",
    "    diff[i] = DCNN_pred[i]-labeldata_array[i]\n",
    "\n",
    "# evaluate accuracy of model\n",
    "print(\"Average Absolute GVI error is: %f\" % np.mean(np.abs(diff)))\n",
    "percentile_result = np.percentile(diff, [5, 95])\n",
    "print(\"5-95 percentile of Absolute GVI error is (%f, %f)\" %\n",
    "      (percentile_result[0], percentile_result[1]))\n",
    "print(\"Correlation of predicted and true GVI is: %f\" %\n",
    "      np.corrcoef(DCNN_pred.T, labeldata_array.T)[0, 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test unsupervised classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_GVI_pred(images):\n",
    "    red = images[:, :, :, 0]\n",
    "    green = images[:, :, :, 1]\n",
    "    blue = images[:, :, :, 2]\n",
    "\n",
    "    diff_1 = green - red\n",
    "    diff_2 = green - blue\n",
    "\n",
    "    diff_1[diff_1 < 0] = 0\n",
    "    diff_2[diff_2 < 0] = 0\n",
    "\n",
    "    Diff = diff_1 * diff_2\n",
    "\n",
    "    unsupervised_GVI_pred =[]\n",
    "\n",
    "    for i in range(len(Diff)):\n",
    "        pred = (np.sum(Diff[i] != 0) ) / (224*224)\n",
    "        unsupervised_GVI_pred.append(pred)\n",
    "\n",
    "    unsupervised_GVI_pred = np.array(unsupervised_GVI_pred)\n",
    "\n",
    "    return unsupervised_GVI_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34339126, 0.60947465, 0.4091199 , 0.35598693, 0.18831712,\n",
       "       0.33527982, 0.1419603 , 0.03824538, 0.06752232, 0.16675303,\n",
       "       0.67332988, 0.3446867 , 0.53730867, 0.5966199 , 0.39365434,\n",
       "       0.47341358, 0.4171317 , 0.6310786 , 0.5840043 , 0.63408801,\n",
       "       0.46314971, 0.38113839, 0.60479114, 0.73307956, 0.00984534,\n",
       "       0.04615753, 0.0180963 , 0.05604273, 0.0609654 , 0.01638233,\n",
       "       0.08141342, 0.19391741, 0.23447465, 0.30897242, 0.25751355,\n",
       "       0.08689413, 0.71906888, 0.57820472, 0.58645568, 0.66344467,\n",
       "       0.55245536, 0.68755979, 0.48883929, 0.23102679, 0.29972497])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsupervised_GVI_pred = unsupervised_GVI_pred(imgdata_array)\n",
    "unsupervised_GVI_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Absolute GVI error is: 0.073144\n",
      "5-95 percentile of Absolute GVI error is (-0.114872, 0.182529)\n",
      "Correlation of predicted and true GVI is: 0.909168\n"
     ]
    }
   ],
   "source": [
    "# compute difference between prediction and true GVI\n",
    "diff = np.zeros([len(unsupervised_GVI_pred), 1])\n",
    "for i in range(len(unsupervised_GVI_pred)):\n",
    "    diff[i] = unsupervised_GVI_pred[i]-labeldata_array[i]\n",
    "\n",
    "# evaluate accuracy of model\n",
    "print(\"Average Absolute GVI error is: %f\" % np.mean(np.abs(diff)))\n",
    "percentile_result = np.percentile(diff, [5, 95])\n",
    "print(\"5-95 percentile of Absolute GVI error is (%f, %f)\" %\n",
    "      (percentile_result[0], percentile_result[1]))\n",
    "print(\"Correlation of predicted and true GVI is: %f\" %\n",
    "      np.corrcoef(unsupervised_GVI_pred.T, labeldata_array.T)[0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b8dee3f82a3892fa7c344bf9c6d3692e70f79ca43cea6847dd76dd904fe1823"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
